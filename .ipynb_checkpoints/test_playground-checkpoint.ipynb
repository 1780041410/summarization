{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxiang/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import os\n",
    "# to load data from the test file\n",
    "from utils.create_datasets import SumDatasets\n",
    "# To load the data sets here, also we will create some examples to explore torch\n",
    "data_dir = '../data/'\n",
    "from utils import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_dataset = SumDatasets(os.path.join(data_dir, 'features-600-40_v2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "tensors used as indices must be long or byte tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cbbd1b639870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexample_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# assume we have a batch data of 20 items.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moriginal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moriginal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content_len'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data0/chenxiang/Sep/bytecup-2018/bytecup_competition/summarization/utils/create_datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mfeatures_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mfeatures_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data0/chenxiang/Sep/bytecup-2018/bytecup_competition/summarization/utils/create_datasets.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, features_1, features_2, features_3, features_4)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0msorted_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# sort will return both the ascending sorted value and also the sorted index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mreverse_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# this will contain the batch_size-1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0msorted_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_length\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreverse_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreverse_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0mfeatures_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorted_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mfeatures_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorted_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: tensors used as indices must be long or byte tensors"
     ]
    }
   ],
   "source": [
    "features_1, features_2, features_3, features_4 = sum_dataset[0:20] # assume we have a batch data of 20 items.\n",
    "original_data = pd.read_csv(os.path.join(data_dir, 'test_data.csv'), encoding='utf-8')\n",
    "original_data['content_len'] = original_data.content.apply(lambda x: len(x.split()))\n",
    "display(original_data.head(n=20))\n",
    "display(example_1[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "hidden_dim = 10\n",
    "# for the padding index 0 and the Unktoken vocab_size + 1, so there will be NUM_WORDS+2\n",
    "# tokens\n",
    "embedding = nn.Embedding(config.NUM_WORDS +2, embedding_dim=embedding_dim)\n",
    "lstm = nn.LSTM(embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(example_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 600, 10])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5158, 0.5986, 0.5767, 0.6330, 0.6154, 0.5766, 0.5469, 0.5183, 0.5927,\n",
       "         0.6202],\n",
       "        [0.7223, 0.7004, 0.7794, 0.7969, 0.6252, 0.6994, 0.6700, 0.5775, 0.7517,\n",
       "         0.5574],\n",
       "        [0.7473, 0.7252, 0.7682, 0.7023, 0.5624, 0.8189, 0.6409, 0.5131, 0.7309,\n",
       "         0.4857],\n",
       "        [0.5584, 0.6599, 0.6808, 0.7636, 0.5259, 0.7098, 0.5762, 0.4847, 0.6862,\n",
       "         0.6399],\n",
       "        [0.6476, 0.7076, 0.5770, 0.7636, 0.6496, 0.6973, 0.7276, 0.4431, 0.7674,\n",
       "         0.7345],\n",
       "        [0.6452, 0.7501, 0.7968, 0.8239, 0.5946, 0.7437, 0.7452, 0.5760, 0.7495,\n",
       "         0.7888],\n",
       "        [0.6735, 0.7684, 0.7626, 0.8101, 0.5257, 0.6962, 0.7921, 0.6199, 0.6625,\n",
       "         0.6860],\n",
       "        [0.6611, 0.7546, 0.9221, 0.8342, 0.5152, 0.5993, 0.5278, 0.5426, 0.7551,\n",
       "         0.7246],\n",
       "        [0.6412, 0.7144, 0.7900, 0.6860, 0.5302, 0.7327, 0.5842, 0.4725, 0.6623,\n",
       "         0.7129],\n",
       "        [0.6147, 0.6282, 0.7176, 0.7142, 0.7873, 0.7952, 0.7722, 0.4929, 0.7931,\n",
       "         0.7722],\n",
       "        [0.7130, 0.8281, 0.7118, 0.6628, 0.5510, 0.8526, 0.5382, 0.5779, 0.7048,\n",
       "         0.6671],\n",
       "        [0.7105, 0.6889, 0.8545, 0.7935, 0.5874, 0.7565, 0.5195, 0.5474, 0.6614,\n",
       "         0.6103],\n",
       "        [0.6711, 0.8160, 0.7281, 0.7006, 0.6739, 0.6710, 0.5834, 0.6172, 0.7166,\n",
       "         0.6096],\n",
       "        [0.7083, 0.8135, 0.7404, 0.7398, 0.7331, 0.6695, 0.7750, 0.5434, 0.6921,\n",
       "         0.5824],\n",
       "        [0.6519, 0.7127, 0.8443, 0.7323, 0.5114, 0.7547, 0.7795, 0.5572, 0.7423,\n",
       "         0.6289],\n",
       "        [0.7332, 0.7236, 0.8277, 0.7639, 0.4920, 0.6111, 0.5906, 0.5000, 0.7667,\n",
       "         0.7029],\n",
       "        [0.6660, 0.6698, 0.7830, 0.7672, 0.6545, 0.7520, 0.8619, 0.5607, 0.7496,\n",
       "         0.7822],\n",
       "        [0.7547, 0.7105, 0.7498, 0.7901, 0.7642, 0.7862, 0.6442, 0.6601, 0.7336,\n",
       "         0.6920],\n",
       "        [0.6630, 0.7814, 0.7607, 0.8209, 0.5148, 0.7510, 0.6068, 0.5805, 0.7824,\n",
       "         0.6844],\n",
       "        [0.6298, 0.7752, 0.6936, 0.7296, 0.6192, 0.7780, 0.5878, 0.7786, 0.7278,\n",
       "         0.6569]], grad_fn=<MaxBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeded_x = embedding(x)\n",
    "output, hidden = lstm(embeded_x)\n",
    "h = output.contiguous()\n",
    "display(h.shape)\n",
    "max_h, _ = h.max(dim=1) # find each batch's maximum hidden state\n",
    "display(max_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_c, h_ = hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 600, 10])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_c.unsqueeze(0).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
