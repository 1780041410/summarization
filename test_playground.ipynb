{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from models.seq2seq import Seq2seq, EncoderRNN, DecoderRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 100\n",
    "embedding_dim = 30\n",
    "embedding_matrix = torch.randn((vocab_size, embedding_dim))\n",
    "hidden_size = 20\n",
    "n_layers = 2\n",
    "bidirectional =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (input_dropout): Dropout(p=0)\n",
      "  (embedding): Embedding(100, 30)\n",
      "  (rnn): LSTM(30, 20, num_layers=2, batch_first=True, bidirectional=True)\n",
      ")\n",
      "Dropout(p=0)\n",
      "Embedding(100, 30)\n",
      "LSTM(30, 20, num_layers=2, batch_first=True, bidirectional=True)\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(vocab_size=vocab_size, max_len=10, hidden_size=hidden_size, \n",
    "                    embedding_dim=embedding_dim, n_layers=n_layers, bidirectional=True,\n",
    "                    rnn_cell = 'lstm', variable_lengths = False, embedding=embedding_matrix,\n",
    "                    update_embedding = True)\n",
    "\n",
    "for idx, m in enumerate(encoder.modules()):\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 假设有下面的参数作为输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_Var = torch.randint(low=0, high=100, size = (3, 4))\n",
    "# WITH BATCH_SIZE =3 AND LENGHT OF EACH BATCH AS 4\n",
    "inputs_Var =inputs_Var.to(torch.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 40])\n",
      "torch.Size([4, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "outputs, hidden = encoder(inputs_Var)\n",
    "print(outputs.shape)     # batch_size, seq_lens, num_directions*hidden_size\n",
    "cell_state, hidden_state = hidden\n",
    "print(cell_state.shape)  # num_layer*birdectional , batch_size, hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_vocab_size = 50\n",
    "decoder_max_len = 10\n",
    "decoder_hidden_size = 40  # will be inline with the encoder's bidirectional, because of the lstm output\n",
    "decoder_embedding = 30\n",
    "decoder_embedding_matrix = torch.randn((decoder_vocab_size, decoder_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_0 = DecoderRNN(decoder_vocab_size,decoder_max_len, embedding_dim=decoder_embedding, hidden_size=decoder_hidden_size, sos_id=0, eos_id=1,\n",
    "                    n_layers=2, rnn_cell = 'lstm',bidirectional=True, use_attention=True, embedding = embedding_matrix)\n",
    "# decoder_1 = DecoderRNN(decoder_vocab_size,decoder_max_len, hidden_size=hidden_size, sos_id=0, eos_id=1,\n",
    "#                     n_layers=1, rnn_cell = 'lstm', use_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2seq(\n",
      "  (encoder): EncoderRNN(\n",
      "    (input_dropout): Dropout(p=0)\n",
      "    (embedding): Embedding(100, 30)\n",
      "    (rnn): LSTM(30, 20, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (decoder): DecoderRNN(\n",
      "    (input_dropout): Dropout(p=0)\n",
      "    (embedding): Embedding(50, 30)\n",
      "    (rnn): LSTM(30, 40, num_layers=2, batch_first=True)\n",
      "    (attention): Attention(\n",
      "      (linear_out): Linear(in_features=80, out_features=40, bias=True)\n",
      "    )\n",
      "    (out): Linear(in_features=40, out_features=50, bias=True)\n",
      "  )\n",
      ")\n",
      "EncoderRNN(\n",
      "  (input_dropout): Dropout(p=0)\n",
      "  (embedding): Embedding(100, 30)\n",
      "  (rnn): LSTM(30, 20, num_layers=2, batch_first=True, bidirectional=True)\n",
      ")\n",
      "Dropout(p=0)\n",
      "Embedding(100, 30)\n",
      "LSTM(30, 20, num_layers=2, batch_first=True, bidirectional=True)\n",
      "DecoderRNN(\n",
      "  (input_dropout): Dropout(p=0)\n",
      "  (embedding): Embedding(50, 30)\n",
      "  (rnn): LSTM(30, 40, num_layers=2, batch_first=True)\n",
      "  (attention): Attention(\n",
      "    (linear_out): Linear(in_features=80, out_features=40, bias=True)\n",
      "  )\n",
      "  (out): Linear(in_features=40, out_features=50, bias=True)\n",
      ")\n",
      "Dropout(p=0)\n",
      "Embedding(50, 30)\n",
      "LSTM(30, 40, num_layers=2, batch_first=True)\n",
      "Attention(\n",
      "  (linear_out): Linear(in_features=80, out_features=40, bias=True)\n",
      ")\n",
      "Linear(in_features=80, out_features=40, bias=True)\n",
      "Linear(in_features=40, out_features=50, bias=True)\n"
     ]
    }
   ],
   "source": [
    "my_seq2seq = Seq2seq(encoder, decoder_0)\n",
    "for idx, m in enumerate(my_seq2seq.modules()):\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 21,  28],\n",
       "        [ 37,  32],\n",
       "        [ 24,  19]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_variables = torch.randint(low=0, high = 40, size=(3, 2))\n",
    "target_variables = target_variables.to(torch.int64)\n",
    "target_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(outputs.shape)\n",
    "# print(hidden)\n",
    "# print(target_variables.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =my_seq2seq(inputs_Var, target_variable=target_variables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
