{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxiang/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import logging\n",
    "import torchtext\n",
    "from IPython.display import display\n",
    "from trainer.supervised_trainer import SupervisedTrainer\n",
    "from models.seq2seq import EncoderRNN, DecoderRNN, Seq2seq\n",
    "from seq2seq.utils import SourceField, TargetField\n",
    "from seq2seq.optim import Optimizer\n",
    "from seq2seq.loss import Perplexity\n",
    "from seq2seq.evaluator import Predictor\n",
    "from torchtext.data import Field\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from torchtext.data import TabularDataset\n",
    "from seq2seq.utils import Checkpoint\n",
    "import csv\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was the year that felt like 50 years. We ...</td>\n",
       "      <td>21 Stories Our Readers Loved in 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gary Vaynerchuk once told a 20 year old Taylor...</td>\n",
       "      <td>What To Do After Graduating College</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  This was the year that felt like 50 years. We ...   \n",
       "1  Gary Vaynerchuk once told a 20 year old Taylor...   \n",
       "\n",
       "                                  title  id  \n",
       "0  21 Stories Our Readers Loved in 2017   0  \n",
       "1   What To Do After Graduating College   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '../data/'\n",
    "file_name = 'train_data.csv'\n",
    "dev_name = 'val_data.csv'\n",
    "train_data = pd.read_csv(os.path.join(data_dir, file_name), encoding='utf-8')\n",
    "display(train_data.head(n=2))\n",
    "csv.field_size_limit(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = \"0123456789\"\n",
    "table = {ord(char): None for char in to_remove}\n",
    "def tokenizer(sentences):\n",
    "    sentences = sentences.lower()\n",
    "    sentences = sentences.translate(table)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentences)\n",
    "    filtered_words = [w for w in tokens]\n",
    "    return filtered_words\n",
    "\n",
    "max_encoder_len = 800\n",
    "min_decoder_len = 1\n",
    "content, title = SourceField(tokenize=tokenizer), TargetField(tokenize=tokenizer)\n",
    "def len_filter(example):\n",
    "    return len(example.content) <= max_encoder_len and len(example.title) >= min_decoder_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 9s, sys: 19.3 s, total: 3min 28s\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tv_datafields = [('content', content), ('title', title), ('id', None)]  # must order the data format with the csv file.\n",
    "trn = TabularDataset(path=os.path.join(data_dir, file_name), \n",
    "                     format='csv', fields=tv_datafields, skip_header=True,\n",
    "                     filter_pred=len_filter)\n",
    "\n",
    "dev = TabularDataset(path=os.path.join(data_dir, dev_name),\n",
    "                    format='csv', fields = tv_datafields, skip_header=True,\n",
    "                    filter_pred=len_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "content.build_vocab(trn, max_size = 50000)\n",
    "title.build_vocab(dev, max_size=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 7215050),\n",
       " ('to', 3798408),\n",
       " ('and', 3324064),\n",
       " ('a', 3130495),\n",
       " ('of', 2999731),\n",
       " ('in', 2567508),\n",
       " ('s', 1543622),\n",
       " ('that', 1397337),\n",
       " ('for', 1383377),\n",
       " ('is', 1297595)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('<sos>', 16625),\n",
       " ('<eos>', 16625),\n",
       " ('to', 4879),\n",
       " ('the', 3629),\n",
       " ('in', 3310),\n",
       " ('s', 3285),\n",
       " ('of', 2753),\n",
       " ('for', 2532),\n",
       " ('a', 1957),\n",
       " ('and', 1853)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(content.vocab.freqs.most_common(10))\n",
    "display(title.vocab.freqs.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab = content.vocab\n",
    "output_vocab = title.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**建立预训练的embedding matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50002, 200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find 2446 unknow words in encoder vocab\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20002, 200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find 1186 unknow words in word2vec\n"
     ]
    }
   ],
   "source": [
    "# load the pretrainde model here to initialize the embedding matrix here.\n",
    "word_to_vec_path = '../data/embedding_matrix/glove/glove.6B.200d.txt'\n",
    "def get_eng_vec(path= word_to_vec_path):\n",
    "    word_to_vec = dict()\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            line=line.split(' ')\n",
    "            word_to_vec[line[0]]= [float(f) for f in line[1:]]\n",
    "    return word_to_vec\n",
    "\n",
    "word_to_vec = get_eng_vec()\n",
    "\n",
    "encoder_embedding_matrix = np.random.randn(len(content.vocab), 200)\n",
    "display(encoder_embedding_matrix.shape)\n",
    "unknow_words = []\n",
    "for index in range(encoder_embedding_matrix.shape[0]):\n",
    "    word = content.vocab.itos[index]\n",
    "    try:\n",
    "        vector = word_to_vec[word]\n",
    "        encoder_embedding_matrix[index, ] = vector\n",
    "    except KeyError:\n",
    "        unknow_words.append(word)\n",
    "print(\"find {} unknow words in encoder vocab\".format(len(unknow_words)))\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "decoder_embedding_matrix = np.random.randn(len(title.vocab), 200)\n",
    "display(decoder_embedding_matrix.shape)\n",
    "unknow_words = 0\n",
    "for index in range(decoder_embedding_matrix.shape[0]):\n",
    "    word = title.vocab.itos[index]\n",
    "    try: # try to find the word in the word_to_vec:\n",
    "        vector = word_to_vec[word]\n",
    "        decoder_embedding_matrix[index, ] = vector\n",
    "    except KeyError:\n",
    "        unknow_words += 1\n",
    "        pass\n",
    "print(\"find {} unknow words in word2vec\".format(unknow_words))\n",
    "\n",
    "np.save('../data/embedding_matrix/encoder_embedding_{}_200.npy'.format(len(content.vocab)), encoder_embedding_matrix)\n",
    "np.save('../data/embedding_matrix/decoder_embedding_{}_200.npy'.format(len(title.vocab)),decoder_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxiang/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# build the model here.\n",
    "weight = torch.ones(len(title.vocab))\n",
    "pad = title.vocab.stoi[title.pad_token]\n",
    "loss = Perplexity(weight, pad)\n",
    "seq2seq = None\n",
    "optimizer = None\n",
    "hidden_size = 100\n",
    "bidirectional = True\n",
    "embedding_dim = 200\n",
    "# must notice to convert the embedding matrix to float32, by default, numpy\n",
    "# just convert the data as float64, which is double format\n",
    "encoder_embedding_matrix = torch.from_numpy(np.load('../data/embedding_matrix/encoder_embedding_50002_200.npy').astype('float32'))\n",
    "decoder_embedding_matrix = torch.from_numpy(np.load('../data/embedding_matrix/decoder_embedding_20002_200.npy').astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(len(content.vocab), max_encoder_len, hidden_size, bidirectional=bidirectional, \n",
    "                     dropout_p=0.2, n_layers=2, variable_lengths=True,embedding=encoder_embedding_matrix,\n",
    "                     embedding_dim = embedding_dim, update_embedding=True)\n",
    "decoder = DecoderRNN(len(title.vocab), 20, embedding_dim, hidden_size*2 if bidirectional else hidden_size, dropout_p=0.2, n_layers=2, use_attention=True, \n",
    "                     bidirectional=bidirectional, eos_id = title.eos_id, sos_id = title.sos_id, embedding=decoder_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (input_dropout): Dropout(p=0)\n",
       "    (embedding): Embedding(50002, 200)\n",
       "    (rnn): GRU(200, 100, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (input_dropout): Dropout(p=0)\n",
       "    (embedding): Embedding(20002, 200)\n",
       "    (rnn): GRU(200, 200, num_layers=2, batch_first=True, dropout=0.2)\n",
       "    (attention): Attention(\n",
       "      (linear_out): Linear(in_features=400, out_features=200, bias=True)\n",
       "    )\n",
       "    (out): Linear(in_features=200, out_features=20002, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.cuda()\n",
    "my_seq2seq =Seq2seq(encoder, decoder)\n",
    "my_seq2seq.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in my_seq2seq.parameters():\n",
    "    param.data.uniform_(-0.08, 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 0 to use the GPU:0\n",
    "t = SupervisedTrainer(loss = loss, batch_size=64, checkpoint_every=3e4, print_every=1e3, expt_dir='../data', device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 9%, Train Perplexity: 51.4091\n",
      "Progress: 14%, Train Perplexity: 27.7018\n",
      "Progress: 19%, Train Perplexity: 28.4190\n",
      "Progress: 24%, Train Perplexity: 28.6126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenxiang/anaconda3/lib/python3.6/site-packages/torchtext/data/field.py:321: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train), lengths\n",
      "/home/chenxiang/anaconda3/lib/python3.6/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 1: Train Perplexity: 27.2360, Dev Perplexity: 1151.6935, Accuracy: 0.1395\n",
      "Progress: 29%, Train Perplexity: 22.1622\n",
      "Progress: 34%, Train Perplexity: 24.1649\n",
      "Progress: 39%, Train Perplexity: 24.9394\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-e393b84d0502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_seq2seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_seq2seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data0/chenxiang/Sep/bytecup-2018/bytecup_competition/summarization/trainer/supervised_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, data, num_epochs, resume, dev_data, optimizer, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         self._train_epoches(data, model, num_epochs,\n\u001b[0;32m--> 188\u001b[0;31m                             \u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m                             teacher_forcing_ratio=teacher_forcing_ratio)\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data0/chenxiang/Sep/bytecup-2018/bytecup_competition/summarization/trainer/supervised_trainer.py\u001b[0m in \u001b[0;36m_train_epoches\u001b[0;34m(self, data, model, n_epochs, start_epoch, start_step, dev_data, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mtarget_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;31m# Record average loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data0/chenxiang/Sep/bytecup-2018/bytecup_competition/summarization/trainer/supervised_trainer.py\u001b[0m in \u001b[0;36m_train_batch\u001b[0;34m(self, input_variable, input_lengths, target_variable, model, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Backward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data0/chenxiang/Sep/bytecup-2018/bytecup_competition/summarization/seq2seq/loss.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No loss to back propagate.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_seq2seq = t.train(my_seq2seq, trn, num_epochs=4, dev_data=dev, optimizer=optimizer, teacher_forcing_ratio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class Predictor(object):\n",
    "\n",
    "    def __init__(self, model, src_vocab, tgt_vocab):\n",
    "        \"\"\"\n",
    "        Predictor class to evaluate for a given model.\n",
    "        Args:\n",
    "            model (seq2seq.models): trained model. This can be loaded from a checkpoint\n",
    "                using `seq2seq.util.checkpoint.load`\n",
    "            src_vocab (seq2seq.dataset.vocabulary.Vocabulary): source sequence vocabulary\n",
    "            tgt_vocab (seq2seq.dataset.vocabulary.Vocabulary): target sequence vocabulary\n",
    "        \"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            self.model = model.cuda()\n",
    "        else:\n",
    "            self.model = model.cpu()\n",
    "        self.model.eval()\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "\n",
    "    def get_decoder_features(self, src_seq):\n",
    "        src_id_seq = torch.LongTensor([self.src_vocab.stoi[tok] for tok in src_seq]).view(1, -1)\n",
    "        if torch.cuda.is_available():\n",
    "            src_id_seq = src_id_seq.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            softmax_list, _, other = self.model(src_id_seq, [len(src_seq)])\n",
    "\n",
    "        return other\n",
    "\n",
    "    def predict(self, src_seq):\n",
    "        \"\"\" Make prediction given `src_seq` as input.\n",
    "\n",
    "        Args:\n",
    "            src_seq (list): list of tokens in source language\n",
    "\n",
    "        Returns:\n",
    "            tgt_seq (list): list of tokens in target language as predicted\n",
    "            by the pre-trained model\n",
    "        \"\"\"\n",
    "        other = self.get_decoder_features(src_seq)\n",
    "\n",
    "        length = other['length'][0]\n",
    "\n",
    "        tgt_id_seq = [other['sequence'][di][0].data[0] for di in range(length)]\n",
    "        tgt_seq = [self.tgt_vocab.itos[tok] for tok in tgt_id_seq]\n",
    "        return tgt_seq\n",
    "\n",
    "    def predict_n(self, src_seq, n=1):\n",
    "        \"\"\" Make 'n' predictions given `src_seq` as input.\n",
    "\n",
    "        Args:\n",
    "            src_seq (list): list of tokens in source language\n",
    "            n (int): number of predicted seqs to return. If None,\n",
    "                     it will return just one seq.\n",
    "\n",
    "        Returns:\n",
    "            tgt_seq (list): list of tokens in target language as predicted\n",
    "                            by the pre-trained model\n",
    "        \"\"\"\n",
    "        other = self.get_decoder_features(src_seq)\n",
    "\n",
    "        result = []\n",
    "        for x in range(0, int(n)):\n",
    "            length = other['topk_length'][0][x]\n",
    "            tgt_id_seq = [other['topk_sequence'][di][0, x, 0].data[0] for di in range(length)]\n",
    "            tgt_seq = [self.tgt_vocab.itos[tok] for tok in tgt_id_seq]\n",
    "            result.append(tgt_seq)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicor = Predictor(my_seq2seq, input_vocab, output_vocab)\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/test_data.csv', encoding='utf-8')\n",
    "test_contents = list(test_data.content)\n",
    "# test_titles = list(test_data.title)[:20]\n",
    "# just use the former 20 sets as the \n",
    "# test_contents =  [tokenizer(content) for content in test_contents]\n",
    "base_line_test_results = [' '.join(sent_tokenize(item)[:2]) for item in test_contents]\n",
    "# test_results = []\n",
    "# for index, content_ in enumerate(test_contents):\n",
    "#     test_title = ' '.join(predicor.predict(content_))\n",
    "#     test_results.append(test_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When someone commits a murder they typically go to extreme lengths to cover up their brutal crime. The harsh prison sentences that go along with killing someone are enough to deter most people from ever wanting to be caught, not to mention the intense social scrutiny they would face.\n",
      "James Milner may not be one of the most exciting players in world football but he is one of the most effective, as underlined by the fact that the Liverpool ace is on the verge of making Champions League history. Ahead of his side's semi-final first-leg meeting with Roma at Anfield, the England international needs just one more assist to break the tournament's all-time record for a single season.\n",
      "Making fun of people can be a sign that you truly care, and feel comfortable enough within your relationship to gently tease them. This is not the case in the photos below.\n",
      "There are days when the forces that be are just not in your favor, and then there's days where bad things are happening to you and it's mostly your own fault. The people in these photos are having tough days - and far be it for us to laugh at people down on their luck - but if you look it appears that most of them deserve what they got.\n",
      "We don't always get to choose our life's calling. Some people were born to play an instrument, some were born to work with their hands, and others were born to heal people.\n",
      "Some people are destined to have terrible things happen to them, while others have a clandestine angel looking after them. The photos below showcase people who came ridiculously close to dangerous disaster, and somehow managed to escape unscathed.\n",
      "Ronald McDonald, that cheeseburger-slinging maestro of McFlurries, has a completely different identity in Japan. Okay, so it's not that different, but after searches for \"What is Ronald McDonald called in Japan?\"\n",
      "If you've got any unused rewards or coupons saved through your Whole Foods loyalty account, use 'em or lose 'em. May 1 is the last day you'll be able to apply them to purchases at any of the market outposts, according to an email Whole Foods sent out to members.\n",
      "It’s hour three of your flight. You've exhausted the movie selection, you're getting hangry and restless, but just as you revert to playing Uno by yourself, the meal cart comes cruising down the aisle and your eyes light up.\n",
      "Yup, you heard the news right: If you head to Outback Steakhouse today, April 23, you can get a free Bloomin' Onion—thanks to race car driver Kevin Harvick. A little context before you sprint over to your neighborhood location: Harvick drives the No.\n",
      "Gordon Ramsay — king of beef Wellington and teaser of plant-eaters — is going vegan. Rather, the chef's \"going to give this #vegan thing a try.\"\n",
      "Krispy Kreme knows how to keep us coming back for more. After decades of keeping their Original Glazed doughnut pure and simple, they've unleashed a spree of new flavors, all of which have been offered for an extremely limited time.For the newest flavor, which America voted on earlier this year, they're actually giving us a bit of a break.\n",
      "\"Bet you can't eat just one\" may be the Lay's tagline, but the saying could just as easily apply to M&amp;M's. If you've ever been in the presence of a jar of the chocolate candies, you know how easily a handful can turn into three.\n",
      "Internet hoaxers have created fake Starbucks coupons offering people of color one free drink following the arrests of two black men at a Philadelphia store last week.According to BuzzFeed News, one coupon originated in a thread on the forums at 4chan and offered one free beverage of any variety to \"people of color only.\" \"We're sorry.\n",
      "Tech\n",
      "\n",
      "\n",
      "Amazon today announced that Amazon Key, the service that already enables in-home delivery and keyless guest access, now gives customers an option to receive deliveries inside their vehicle. With Amazon Key In-Car, Prime members with compatible vehicles now have the convenience of having packages delivered inside their cars when parked in a publicly accessible area, typically at their home or workplace.\n",
      "verelife.comIn the congregation, we can learn from our brothers and sisters and help one another to stay faithful. Romans 1: 11.\n",
      "verelife.comWe love our brothers and sisters and want to  get along with them. We all make mistakes, but love will help us to keep “forgiving one another freely.”Proverbs 17: 9.\n",
      "Two weeks ago, Khloé Kardashian's life changed in several big ways all at once. First, videos surfaced that appeared to show Khloé's boyfriend (and the father of her then-unborn baby) cheating on her multiple times with multiple women over the course of her pregnancy.\n",
      "Let’s be real, humans are completely fascinated with animals; these irresistible creatures can keep us captivated for hours at a time. We capture their actions on videos and every-so-often we take photos when they do randomly funny things.\n",
      "People love to dress their pets up in costumes. Normally the pets either tolerate it, or downright hate it.\n",
      "Most pet owners are guilty of spoiling their little furry friends, but there are some who take the idea of a pet and owner companionship to a whole new level. It starts with slipping them table scraps, and ends with letting them in bed and dressing them like mini children.\n"
     ]
    }
   ],
   "source": [
    "for index, title_ in enumerate(base_line_test_results):\n",
    "    print(title_)\n",
    "    if index == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this man s brutal is the chilling <unk> to the\n",
      "liverpool <unk> record of champions league\n",
      "people people are funny funny funny funny funny funny\n",
      "these are the 10 most relatable ever are ever\n",
      "13 people are not the most\n",
      "10 things you should know about your <unk>\n",
      "<unk> s s s s s s s\n",
      "amazon s prime prime prime prime prime the\n",
      "<unk> to get a <unk> for for for\n",
      "this you can get a free <unk> <unk> <unk>\n",
      "gordon ramsay of a <unk> ramsay a ramsay of a cheese\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "this is a <unk> <unk> <unk> <unk> <unk> a a\n",
      "twitter <unk> <unk> <unk> people from <unk> of of\n",
      "amazon delivery delivery delivery delivery delivery delivery delivery delivery delivery\n",
      "<unk> <unk> <unk> <unk>\n",
      "how to do to\n",
      "khloé khloé s kardashian s kardashian about her baby s pregnancy\n",
      "10 10 <unk> <unk> <unk> <unk>\n",
      "these the cutest to wear a cat in the a\n",
      "this are the the <unk> <unk> <unk> <unk> <unk>\n"
     ]
    }
   ],
   "source": [
    "test_results = [item[:-6] for item in test_results]\n",
    "for index, title_ in enumerate(test_results):\n",
    "    print(title_)\n",
    "    if index == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = '../data/result'\n",
    "if not os.path.exists(test_data_dir):\n",
    "    os.mkdir(test_data_dir)\n",
    "else:\n",
    "    shutil.rmtree(test_data_dir)\n",
    "    os.mkdir(test_data_dir)\n",
    "\n",
    "for i in range(len(base_line_test_results)):\n",
    "    with open(os.path.join(test_data_dir, str(i+1)+'.txt'), 'w') as f:\n",
    "        f.write(test_results[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
